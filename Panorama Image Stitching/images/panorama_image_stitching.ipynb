{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7616efc3",
      "metadata": {
        "id": "7616efc3"
      },
      "source": [
        "# Panorama Image Stitching\n",
        "You will generate a stitched panorama image from multiple input images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cb2c86",
      "metadata": {
        "id": "a1cb2c86"
      },
      "outputs": [],
      "source": [
        "# Load required Libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb3ccbc",
      "metadata": {
        "id": "1fb3ccbc"
      },
      "source": [
        "## Read in the images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8b253f7",
      "metadata": {
        "id": "c8b253f7"
      },
      "outputs": [],
      "source": [
        "# read images\n",
        "path = 'images'\n",
        "input_path = path + '/set_1/'\n",
        "filenames = [input_path + filename for filename in os.listdir(input_path)]\n",
        "raw_images = [cv2.imread(filename) for filename in filenames]\n",
        "count = len(raw_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "552ea0af",
      "metadata": {
        "id": "552ea0af"
      },
      "source": [
        "## Reorder the images\n",
        "As this assignment will require the merge of multiple images, we need to do some alignment of the images. THe idea is to reset the order of the images, and to make the centre image the \"source\" image, and to then extend the panorama to both sides. \\\n",
        "\n",
        "As this is not the key learning from this assignment, the code is provided, no modifications are required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d718035",
      "metadata": {
        "id": "6d718035"
      },
      "outputs": [],
      "source": [
        "# reset the order of the images to make the center one is the source image, and extend to both sides\n",
        "images = []\n",
        "new_idx = (count - 1) // 2\n",
        "k = -1\n",
        "for i in range(count):\n",
        "    new_idx = new_idx + k * i\n",
        "    images.append(raw_images[new_idx])\n",
        "    k *= -1\n",
        "\n",
        "# initialize the source image\n",
        "img_src = images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "308118da",
      "metadata": {
        "id": "308118da"
      },
      "source": [
        "## Perform panorama stitching\n",
        "\n",
        "In this section, implement the panorama image stitching. Note that there are multiple approaches that will work to achieve this, and you can find multiple examples online. In this assignment, we will work through one possible implementation.\n",
        "\n",
        "Note that in this example, the goal is to merge multiple images (many demos online only merge two images). Also, for this example, we will consider horizontal merges only. It is relatively straight forward to extend this implementation to consider vertical panorama stitching too.\n",
        "\n",
        "Note: with this implementation, the quality varies with the number of input images (merging 2 images is ok, but for more than 2, the perspective isn't very good). So try varying the number of images used in the merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee7987f",
      "metadata": {
        "id": "cee7987f",
        "outputId": "c3cba61f-c073-4745-a4e8-0caa7fd821ef"
      },
      "outputs": [],
      "source": [
        "# the image need to stitch\n",
        "orb = cv2.ORB_create()\n",
        "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
        "for i in range(1, len(images)):\n",
        "    img_dst = images[i]\n",
        "    # make sure to merge from left to right\n",
        "    if i % 2 == 0:\n",
        "        img_src, img_dst = img_dst, img_src\n",
        "\n",
        "    # detects keypoints and computes the descriptors for \"source\" and \"destination\" images (hint: use ORB features)\n",
        "    kp1, des1 = orb.detectAndCompute(img_src, None)\n",
        "    kp2, des2 = orb.detectAndCompute(img_dst, None)\n",
        "    # create a brute foce matching function, and calculate the matches\n",
        "    matches = bf.match(des1, des2)\n",
        "\n",
        "    # sort the matches by distance\n",
        "    matches = sorted(matches, key = lambda x: x.distance)\n",
        "\n",
        "    # Keep only the top 50 matches\n",
        "    matches = matches[:50]\n",
        "\n",
        "    # Get the keypoints from the matches\n",
        "    src_pts = np.zeros((len(matches), 2), dtype=np.float32).reshape(-1, 1, 2)\n",
        "    dst_pts = np.zeros((len(matches), 2), dtype=np.float32).reshape(-1, 1, 2)\n",
        "    for i, match in enumerate(matches):\n",
        "        src_pts[i, :] = kp1[match.queryIdx].pt\n",
        "        dst_pts[i, :] = kp2[match.trainIdx].pt\n",
        "\n",
        "    # Compute the homography matrix using RANSAC\n",
        "    M, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
        "    # show the keypoint matches (hint: use the opencv drawMatches function)\n",
        "    image_matches = cv2.drawMatches(img_src, kp1, img_dst, kp2, matches, None)\n",
        "    # show matched points image\n",
        "    plt.figure(figsize = (15, 15))\n",
        "    plt.imshow(image_matches)\n",
        "    plt.axis('off')\n",
        "    # get the height and width of the original images\n",
        "    h1, w1, p1 = img_src.shape\n",
        "    h2, w2, p2 = img_dst.shape\n",
        "    h = np.maximum(h1, h2)\n",
        "    w = np.maximum(w1, w2)\n",
        "\n",
        "    move_dis = int(np.maximum(dst_pts[0][0][0], src_pts[0][0][0]))\n",
        "\n",
        "    # apply perspective correction (hint: use opencv warpPerspective. Set the width and height to (w1 + w2 - move_dis, h))\n",
        "    img_transform = cv2.warpPerspective(img_dst, M, (w1 + w2 - move_dis, h))\n",
        "    # combine the source image to the transformed image\n",
        "    img_transform[0:img_src.shape[0], 0:img_src.shape[1]] = img_src\n",
        "    # use img_transform as the source image for the next iteration of the loop\n",
        "    img_src = img_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bdf02c",
      "metadata": {
        "id": "33bdf02c",
        "outputId": "5db952e9-c208-49a5-9c3d-bd217c27db0e"
      },
      "outputs": [],
      "source": [
        "# Display final panorama\n",
        "plt.figure(figsize = (15,15))\n",
        "plt.axis('off')\n",
        "plt.imshow(img_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b875258",
      "metadata": {
        "id": "7b875258"
      },
      "outputs": [],
      "source": [
        "def panorama_stitching(images, reduction = 0):\n",
        "    # read images\n",
        "    path = 'images'\n",
        "    input_path = path + '/' + images + '/'\n",
        "    filenames = [input_path + filename for filename in os.listdir(input_path)]\n",
        "    raw_images = [cv2.imread(filename) for filename in filenames]\n",
        "    count = len(raw_images)\n",
        "    # reset the order of the images to make the center one is the source image, and extend to both sides\n",
        "    images = []\n",
        "    new_idx = (count - 1) // 2\n",
        "    k = -1\n",
        "    for i in range(count):\n",
        "        new_idx = new_idx + k * i\n",
        "        images.append(raw_images[new_idx])\n",
        "        k *= -1\n",
        "\n",
        "    # initialize the source image\n",
        "    img_src = images[0]\n",
        "    # the image need to stitch\n",
        "    orb = cv2.ORB_create()\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck = True)\n",
        "    for i in range(1, len(images)):\n",
        "        img_dst = images[i]\n",
        "        # make sure to merge from left to right\n",
        "        if i % 2 == 0:\n",
        "            img_src, img_dst = img_dst, img_src\n",
        "\n",
        "        # detects keypoints and computes the descriptors for \"source\" and \"destination\" images (hint: use ORB features)\n",
        "        kp1, des1 = orb.detectAndCompute(img_src, None)\n",
        "        kp2, des2 = orb.detectAndCompute(img_dst, None)\n",
        "        # create a brute foce matching function, and calculate the matches\n",
        "        matches = bf.match(des1, des2)\n",
        "\n",
        "        # sort the matches by distance\n",
        "        matches = sorted(matches, key = lambda x: x.distance)\n",
        "\n",
        "        # Keep only the top 50 matches\n",
        "        matches = matches[:50]\n",
        "\n",
        "        # Get the keypoints from the matches\n",
        "        src_pts = np.zeros((len(matches), 2), dtype=np.float32).reshape(-1, 1, 2)\n",
        "        dst_pts = np.zeros((len(matches), 2), dtype=np.float32).reshape(-1, 1, 2)\n",
        "        for i, match in enumerate(matches):\n",
        "            src_pts[i, :] = kp1[match.queryIdx].pt\n",
        "            dst_pts[i, :] = kp2[match.trainIdx].pt\n",
        "\n",
        "        # Compute the homography matrix using RANSAC\n",
        "        M, _ = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)\n",
        "        # show the keypoint matches (hint: use the opencv drawMatches function)\n",
        "        image_matches = cv2.drawMatches(img_src, kp1, img_dst, kp2, matches, None)\n",
        "        # show matched points image\n",
        "        plt.figure(figsize = (15, 15))\n",
        "        plt.imshow(image_matches)\n",
        "        plt.axis('off')\n",
        "        # get the height and width of the original images\n",
        "        h1, w1, p1 = img_src.shape\n",
        "        h2, w2, p2 = img_dst.shape\n",
        "        h = np.maximum(h1, h2)\n",
        "        w = np.maximum(w1, w2)\n",
        "\n",
        "        move_dis = int(np.maximum(dst_pts[0][0][0], src_pts[0][0][0]))\n",
        "\n",
        "        # apply perspective correction (hint: use opencv warpPerspective. Set the width and height to (w1 + w2 - move_dis, h))\n",
        "        img_transform = cv2.warpPerspective(img_dst, M, (w1 + w2 - move_dis, h))\n",
        "        # combine the source image to the transformed image\n",
        "        img_transform[0:img_src.shape[0], 0:img_src.shape[1]] = img_src\n",
        "        # use img_transform as the source image for the next iteration of the loop\n",
        "        img_src = img_transform\n",
        "        plt.figure(figsize = (15, 15))\n",
        "        plt.imshow(img_transform)\n",
        "        plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "860fb3fc",
      "metadata": {
        "id": "860fb3fc",
        "outputId": "21f994a5-c44c-4ffc-d70e-d63692110920"
      },
      "outputs": [],
      "source": [
        "for i in range(1):\n",
        "    panorama_stitching('set_2', i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33eeaa39",
      "metadata": {
        "id": "33eeaa39",
        "outputId": "e3cc87b7-4146-485c-c0e6-acc4e0c4557b"
      },
      "outputs": [],
      "source": [
        "for i in range(1):\n",
        "    panorama_stitching('set_3', i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1893a841",
      "metadata": {
        "id": "1893a841",
        "outputId": "f5e675c1-4643-4ed7-ab0e-d3a0daea998f"
      },
      "outputs": [],
      "source": [
        "for i in range(1):\n",
        "    panorama_stitching('set_4', i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1990365",
      "metadata": {
        "id": "a1990365",
        "outputId": "53582f00-f118-4283-ad78-b18f73190c78"
      },
      "outputs": [],
      "source": [
        "for i in range(1):\n",
        "    panorama_stitching('set_5', i)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
